"""
ä» compression_results.json ä¸­æå– control points çš„ bin distribution
ä¿å­˜ä¸º control_point_bin_distribution.npyï¼Œä¾› tokenizer ä½¿ç”¨
ä»…å¤„ç† 6 ä¸ªç»´åº¦ï¼šx, y, z, yaw, pitch, roll

ä½¿ç”¨ K-Means èšç±»æ‰¾åˆ°æœ€ä¼˜çš„ bin ä¸­å¿ƒï¼Œæœ€å°åŒ–é‡æ„è¯¯å·®
"""

import json
import numpy as np
from pathlib import Path
from tqdm import tqdm
from sklearn.cluster import KMeans


def generate_control_point_bin_distribution(
    json_path: str = "compression_results.json",
    output_path: str = "control_point_bin_distribution.npy",
    n_bins: int = 512,
    n_dims: int = 6
):
    """
    ä» compression_results.json ä¸­æå–æ‰€æœ‰ control points çš„ bin distribution
    
    Args:
        json_path: compression_results.json çš„è·¯å¾„
        output_path: è¾“å‡ºçš„ npy æ–‡ä»¶è·¯å¾„
        n_bins: bin æ•°é‡ï¼ˆé»˜è®¤ 512ï¼‰
        n_dims: ç»´åº¦æ•°ï¼ˆé»˜è®¤ 6ï¼Œä¸åŒ…æ‹¬ gripperï¼‰
    """
    json_path = Path(json_path)
    output_path = Path(output_path)
    
    if not json_path.exists():
        raise FileNotFoundError(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {json_path}")
    
    print(f"ğŸ“– æ­£åœ¨åŠ è½½ {json_path}...")
    with open(json_path, 'r') as f:
        results = json.load(f)
    
    episodes = results.get("episodes", {})
    print(f"âœ“ åŠ è½½äº† {len(episodes)} ä¸ª episodes")
    
    # Step 1: æ”¶é›†å‰ n_dims ä¸ªç»´åº¦çš„ control point æ•°æ®
    print(f"\nğŸ“Š æ­£åœ¨æ”¶é›† {n_dims} ä¸ªç»´åº¦çš„ control points æ•°æ®...")
    all_data = [[] for _ in range(n_dims)]
    
    for ep_idx_str, ep_data in tqdm(episodes.items(), desc="æ”¶é›†ä¸­"):
        bspline = ep_data.get("bspline", {})
        control_points = bspline.get("control_points", [])
        
        if not control_points:
            continue
        
        for dim in range(min(n_dims, len(control_points))):
            all_data[dim].extend(control_points[dim])
    
    print(f"âœ“ æ”¶é›†å®Œæˆ")
    
    # Step 2: ä½¿ç”¨ K-Means æ‰¾åˆ°æœ€ä¼˜çš„ bin ä¸­å¿ƒ
    print(f"\nğŸ¯ ä½¿ç”¨ K-Means è®¡ç®—æœ€ä¼˜çš„ {n_bins} ä¸ª bin ä¸­å¿ƒ...")
    edges = np.zeros((n_dims, n_bins + 1), dtype=np.float32)  # ä¿æŒå…¼å®¹æ€§ï¼Œå­˜å‚¨æ’åºåçš„ç°‡å¿ƒ + è¾¹ç•Œ
    bin_centers_list = []  # å­˜å‚¨æ¯ä¸ªç»´åº¦çš„ç°‡å¿ƒ
    
    dim_names = ['x', 'y', 'z', 'yaw', 'pitch', 'roll']
    
    for dim in range(n_dims):
        if len(all_data[dim]) > 0:
            data_array = np.array(all_data[dim], dtype=np.float32).reshape(-1, 1)
            
            # K-Means èšç±»
            kmeans = KMeans(n_clusters=n_bins, random_state=42, n_init=10, verbose=0)
            kmeans.fit(data_array)
            
            # å¾—åˆ°ç°‡å¿ƒå¹¶æ’åº
            cluster_centers = np.sort(kmeans.cluster_centers_.flatten()).astype(np.float32)
            bin_centers_list.append(cluster_centers)
            
            # æ„é€ è¾¹ç•Œï¼šä¸¤ä¸ªç›¸é‚»ç°‡å¿ƒçš„ä¸­ç‚¹
            # å‰è¾¹ç•Œå’Œåè¾¹ç•Œè®¾ç½®ä¸ºç°‡å¿ƒå¤–ä¾§
            min_val = cluster_centers[0]
            max_val = cluster_centers[-1]
            
            edges[dim, 0] = min_val - (cluster_centers[1] - cluster_centers[0]) / 2 if n_bins > 1 else min_val - 1
            edges[dim, -1] = max_val + (cluster_centers[-1] - cluster_centers[-2]) / 2 if n_bins > 1 else max_val + 1
            
            # ä¸­é—´è¾¹ç•Œæ˜¯ç›¸é‚»ç°‡å¿ƒçš„ä¸­ç‚¹
            for i in range(1, n_bins):
                edges[dim, i] = (cluster_centers[i-1] + cluster_centers[i]) / 2.0
    
    # Step 3: è®¡ç®—ç¦»æ•£åŒ–è¯¯å·®
    print(f"\nğŸ“Š è®¡ç®—ç¦»æ•£åŒ–è¯¯å·®...")
    print(f"{'ç»´åº¦':<8} {'æ•°æ®ç‚¹æ•°':<12} {'èŒƒå›´':<35} {'MaxErr':<12} {'MeanErr':<12} {'StdErr':<12} {'MSE':<12}")
    print("-" * 110)
    
    quantization_errors = []
    for dim in range(n_dims):
        if len(all_data[dim]) > 0:
            data_array = np.array(all_data[dim], dtype=np.float32)
            cluster_centers = bin_centers_list[dim]
            
            # æ‰¾åˆ°æ¯ä¸ªæ•°æ®ç‚¹æœ€è¿‘çš„ç°‡å¿ƒ
            distances = np.abs(data_array[:, np.newaxis] - cluster_centers[np.newaxis, :])
            nearest_idx = np.argmin(distances, axis=1)
            quantized_values = cluster_centers[nearest_idx]
            
            # è®¡ç®—è¯¯å·®
            errors = np.abs(data_array - quantized_values)
            max_err = np.max(errors)
            mean_err = np.mean(errors)
            std_err = np.std(errors)
            mse = np.mean(errors ** 2)
            
            quantization_errors.append({
                'dim': dim_names[dim],
                'max': max_err,
                'mean': mean_err,
                'std': std_err,
                'mse': mse
            })
            
            range_str = f"[{data_array.min():10.4f}, {data_array.max():10.4f}]"
            n_points = len(all_data[dim])
            print(f"{dim_names[dim]:<8} {n_points:<12} {range_str:<35} {max_err:<12.6f} {mean_err:<12.6f} {std_err:<12.6f} {mse:<12.6f}")
    
    print(f"\nğŸ’¡ K-Means æ–¹æ³•è¯´æ˜:")
    print(f"    - æ¯ä¸ªç»´åº¦ç‹¬ç«‹ä½¿ç”¨ K-Means èšç±»ï¼Œå¾—åˆ° {n_bins} ä¸ªæœ€ä¼˜çš„ç°‡å¿ƒ")
    print(f"    - ç°‡å¿ƒä½œä¸ºé‡åŒ–çš„ç›®æ ‡å€¼ï¼Œæœ€å°åŒ–é‡æ„å‡æ–¹è¯¯å·® (MSE)")
    print(f"    - ç›¸æ¯”åˆ†ä½æ•°æ–¹æ³•ï¼Œå¯æ˜¾è‘—é™ä½ max error å’Œ mean error")
    
    # Step 4: ä¿å­˜ edges
    print(f"\nğŸ’¾ ä¿å­˜åˆ° {output_path}...")
    np.save(output_path, edges)
    print(f"âœ“ å®Œæˆï¼Edges å½¢çŠ¶: {edges.shape}")
    
    return edges


if __name__ == "__main__":
    asset_json = Path(__file__).parent.parent / "assets" / "compression_results_v2.json"
    output_npy = Path(__file__).parent / "control_point_bin_distribution.npy"
    
    print(f"ğŸ“ JSON è·¯å¾„: {asset_json}")
    print(f"ğŸ“ è¾“å‡ºè·¯å¾„: {output_npy}\n")
    
    edges = generate_control_point_bin_distribution(
        json_path=str(asset_json),
        output_path=str(output_npy),
        n_bins=512,
        n_dims=6
    )
    
    print(f"\nâœ… å®Œæˆï¼")


# ğŸ“Š è®¡ç®—ç¦»æ•£åŒ–è¯¯å·®...
# ç»´åº¦       æ•°æ®ç‚¹æ•°         èŒƒå›´                                  éç©ºbins     MaxErr       MeanErr      StdErr      
# ----------------------------------------------------------------------------------------------------
# x        41046        [  -50.1885,    52.8019]            512        14.345612    0.065102     0.665614    
# y        41046        [  -69.3363,    72.5234]            512        22.512955    0.084292     0.899412    
# z        41046        [  -98.6969,    39.2960]            512        20.918144    0.082390     0.824966    
# yaw      41046        [  -11.8946,    10.8398]            512        1.921101     0.012413     0.087433    
# pitch    41046        [  -13.9759,    17.5974]            512        3.791125     0.017898     0.164113    
# roll     41046        [  -24.8003,    24.5268]            512        4.152792     0.027434     0.176028    

# ğŸ¯ ä½¿ç”¨ K-Means è®¡ç®—æœ€ä¼˜çš„ 512 ä¸ª bin ä¸­å¿ƒ...

# ğŸ“Š è®¡ç®—ç¦»æ•£åŒ–è¯¯å·®...
# ç»´åº¦       æ•°æ®ç‚¹æ•°         èŒƒå›´                                  MaxErr       MeanErr      StdErr       MSE         
# --------------------------------------------------------------------------------------------------------------
# x        41046        [  -50.1885,    52.8019]            0.248451     0.020642     0.014989     0.000651    
# y        41046        [  -69.3363,    72.5234]            0.350449     0.030767     0.021994     0.001430    
# z        41046        [  -98.6969,    39.2960]            0.361328     0.024287     0.019071     0.000954    
# yaw      41046        [  -11.8946,    10.8398]            0.062275     0.004020     0.003700     0.000030    
# pitch    41046        [  -13.9759,    17.5974]            0.079699     0.005720     0.004743     0.000055    
# roll     41046        [  -24.8003,    24.5268]            0.125874     0.010570     0.009616     0.000204    

# ğŸ’¡ K-Means æ–¹æ³•è¯´æ˜:
#     - æ¯ä¸ªç»´åº¦ç‹¬ç«‹ä½¿ç”¨ K-Means èšç±»ï¼Œå¾—åˆ° 512 ä¸ªæœ€ä¼˜çš„ç°‡å¿ƒ
#     - ç°‡å¿ƒä½œä¸ºé‡åŒ–çš„ç›®æ ‡å€¼ï¼Œæœ€å°åŒ–é‡æ„å‡æ–¹è¯¯å·® (MSE)
#     - ç›¸æ¯”åˆ†ä½æ•°æ–¹æ³•ï¼Œå¯æ˜¾è‘—é™ä½ max error å’Œ mean error