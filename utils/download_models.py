#!/usr/bin/env python3
"""
download_models.py

ä¸‹è½½ VLA è®­ç»ƒæ‰€éœ€çš„æ–°æ¨¡å‹æƒé‡åˆ° HuggingFace ç¼“å­˜ä¸­

æ”¯æŒçš„æ¨¡å‹:
- Qwen3-VL (Qwen2-VL) 2B/7B/72B
- DistilGPT2

ä½¿ç”¨æ–¹æ³•:
    python download_models.py --all                    # ä¸‹è½½æ‰€æœ‰æ¨¡å‹
    python download_models.py --model qwen3-vl-2b      # ä¸‹è½½ç‰¹å®šæ¨¡å‹
    python download_models.py --model distilgpt2      # ä¸‹è½½ DistilGPT2
"""

import argparse
import os
from pathlib import Path
from typing import List

from huggingface_hub import snapshot_download

# æ¨¡å‹æ˜ å°„è¡¨
MODEL_REGISTRY = {
    "qwen3-vl-2b": {
        "hf_path": "Qwen/Qwen3-VL-2B-Instruct",
        "size": "~4.5GB",
        "description": "Qwen3-VL 2B Instruct (ç»Ÿä¸€å¤šæ¨¡æ€æ¨¡å‹)",
    },
    "qwen3-vl-4b": {
        "hf_path": "Qwen/Qwen3-VL-4B-Instruct",
        "size": "~10GB",
        "description": "Qwen3-VL 4B Instruct (ç»Ÿä¸€å¤šæ¨¡æ€æ¨¡å‹)",
    },
    "qwen3-vl-7b": {
        "hf_path": "Qwen/Qwen3-VL-7B-Instruct",
        "size": "~15GB",
        "description": "Qwen3-VL 7B Instruct (ç»Ÿä¸€å¤šæ¨¡æ€æ¨¡å‹)",
    },
    "distilgpt2": {
        "hf_path": "distilgpt2",
        "size": "~320MB",
        "description": "DistilGPT2 (è½»é‡çº§è¯­è¨€æ¨¡å‹ï¼Œç”¨äºè°ƒè¯•)",
    },
}


def download_model(model_name: str, force: bool = False) -> None:
    """
    ä¸‹è½½æŒ‡å®šæ¨¡å‹åˆ° HuggingFace ç¼“å­˜
    
    ä½¿ç”¨ snapshot_download é¿å…ç«‹å³åŠ è½½æ¨¡å‹å¯¼è‡´çš„å…¼å®¹æ€§é—®é¢˜
    
    Args:
        model_name: æ¨¡å‹åç§° (e.g., 'qwen3-vl-2b', 'distilgpt2')
        force: æ˜¯å¦å¼ºåˆ¶é‡æ–°ä¸‹è½½ï¼ˆå³ä½¿å·²ç¼“å­˜ï¼‰
    """
    if model_name not in MODEL_REGISTRY:
        raise ValueError(
            f"Unknown model: {model_name}. "
            f"Available models: {list(MODEL_REGISTRY.keys())}"
        )
    
    model_info = MODEL_REGISTRY[model_name]
    hf_path = model_info["hf_path"]
    size = model_info["size"]
    description = model_info.get("description", "")
    
    print(f"\n{'='*60}")
    print(f"ğŸ“¦ ä¸‹è½½æ¨¡å‹: {model_name}")
    print(f"   è¯´æ˜: {description}")
    print(f"   HF è·¯å¾„: {hf_path}")
    print(f"   é¢„è®¡å¤§å°: {size}")
    print(f"{'='*60}\n")
    
    try:
        # ä½¿ç”¨ snapshot_download ä¸‹è½½æ•´ä¸ªæ¨¡å‹ä»“åº“
        # è¿™æ ·é¿å…äº†ç«‹å³åŠ è½½æ¨¡å‹å¯èƒ½å¯¼è‡´çš„ç‰ˆæœ¬ä¸å…¼å®¹é—®é¢˜
        print(f"æ­£åœ¨ä¸‹è½½ {hf_path}...")
        print(f"æç¤º: ä½¿ç”¨ snapshot_download ä¸‹è½½å®Œæ•´æ¨¡å‹æ–‡ä»¶")
        
        cache_dir = snapshot_download(
            repo_id=hf_path,
            repo_type="model",
            ignore_patterns=["*.msgpack", "*.h5", "*.ot"],  # è·³è¿‡ä¸éœ€è¦çš„æ ¼å¼
            local_files_only=False,
            force_download=force,
        )
        
        print(f"âœ… æ¨¡å‹å·²ä¸‹è½½åˆ°: {cache_dir}")
        print(f"ğŸ‰ {model_name} ä¸‹è½½å®Œæˆ!\n")
        
    except Exception as e:
        print(f"\nâŒ ä¸‹è½½ {model_name} æ—¶å‡ºé”™: {e}\n")
        raise


def main():
    parser = argparse.ArgumentParser(
        description="ä¸‹è½½ VLA è®­ç»ƒæ‰€éœ€çš„æ¨¡å‹æƒé‡åˆ° HuggingFace ç¼“å­˜"
    )
    parser.add_argument(
        "--model",
        type=str,
        choices=list(MODEL_REGISTRY.keys()),
        help="æŒ‡å®šè¦ä¸‹è½½çš„æ¨¡å‹",
    )
    parser.add_argument(
        "--all",
        action="store_true",
        help="ä¸‹è½½æ‰€æœ‰æ¨¡å‹ï¼ˆè­¦å‘Šï¼šæ€»å¤§å° ~165GBï¼‰",
    )
    parser.add_argument(
        "--skip-72b",
        action="store_true",
        help="è·³è¿‡ 72B æ¨¡å‹ï¼ˆä¸ --all ä¸€èµ·ä½¿ç”¨ï¼‰",
    )
    parser.add_argument(
        "--force",
        action="store_true",
        help="å¼ºåˆ¶é‡æ–°ä¸‹è½½ï¼ˆå³ä½¿å·²ç¼“å­˜ï¼‰",
    )
    
    args = parser.parse_args()
    
    # ç¡®å®šè¦ä¸‹è½½çš„æ¨¡å‹åˆ—è¡¨
    if args.all:
        models_to_download = list(MODEL_REGISTRY.keys())
        if args.skip_72b:
            models_to_download = [m for m in models_to_download if m != "qwen3-vl-72b"]
            print("âš ï¸  è·³è¿‡ Qwen3-VL 72B æ¨¡å‹")
    elif args.model:
        models_to_download = [args.model]
    else:
        # é»˜è®¤ä¸‹è½½å°æ¨¡å‹ç”¨äºè°ƒè¯•
        print("æœªæŒ‡å®šæ¨¡å‹ï¼Œé»˜è®¤ä¸‹è½½è½»é‡çº§æ¨¡å‹ï¼š")
        models_to_download = ["qwen3-vl-4b"]
    
    # æ˜¾ç¤ºä¸‹è½½è®¡åˆ’
    print("\n" + "="*60)
    print("ğŸ“‹ ä¸‹è½½è®¡åˆ’:")
    total_size = 0
    for model_name in models_to_download:
        info = MODEL_REGISTRY[model_name]
        print(f"  - {model_name:20s} ({info['size']})")
    print("="*60)
    
    # ç¡®è®¤ä¸‹è½½
    if args.all and not args.skip_72b:
        response = input("\nâš ï¸  å°†ä¸‹è½½æ‰€æœ‰æ¨¡å‹ï¼ˆ~165GBï¼‰ï¼Œç¡®è®¤ç»§ç»­ï¼Ÿ[y/N]: ")
        if response.lower() != 'y':
            print("å·²å–æ¶ˆä¸‹è½½")
            return
    
    # å¼€å§‹ä¸‹è½½
    print("\nğŸš€ å¼€å§‹ä¸‹è½½...\n")
    success_count = 0
    failed_models = []
    
    for i, model_name in enumerate(models_to_download, 1):
        print(f"\n{'#'*60}")
        print(f"# è¿›åº¦: {i}/{len(models_to_download)}")
        print(f"{'#'*60}")
        
        try:
            download_model(model_name, force=args.force)
            success_count += 1
        except Exception as e:
            print(f"âŒ è·³è¿‡ {model_name}")
            failed_models.append(model_name)
    
    # æ€»ç»“
    print("\n" + "="*60)
    print("ğŸ“Š ä¸‹è½½æ€»ç»“:")
    print(f"  âœ… æˆåŠŸ: {success_count}/{len(models_to_download)}")
    if failed_models:
        print(f"  âŒ å¤±è´¥: {', '.join(failed_models)}")
    print("="*60)
    
    # æ˜¾ç¤º HF ç¼“å­˜ä½ç½®
    hf_cache = os.environ.get(
        "HF_HOME",
        os.path.expanduser("~/.cache/huggingface")
    )
    print(f"\nğŸ’¾ æ¨¡å‹å·²ç¼“å­˜åˆ°: {hf_cache}")
    print("\nâœ¨ ç°åœ¨å¯ä»¥è¿è¡Œè®­ç»ƒäº†ï¼")


if __name__ == "__main__":
    main()
