#!/usr/bin/env python3
"""
download_models.py

ä¸‹è½½ VLA è®­ç»ƒæ‰€éœ€çš„æ–°æ¨¡å‹æƒé‡åˆ° HuggingFace ç¼“å­˜ä¸­

æ”¯æŒçš„æ¨¡å‹:
- Qwen2.5-0.5B-Instruct (æ¨èç”¨äº VLA LLM Backbone)
- Qwen2-VL 2B/7B (ç”¨äºå¯¹æ¯”å®éªŒ)
- DistilGPT2 (æ—§è°ƒè¯•æ¨¡å‹)

ä½¿ç”¨æ–¹æ³•:
    python download_models.py                          # é»˜è®¤ä¸‹è½½ Qwen2.5-0.5B
    python download_models.py --model qwen2.5-0.5b     # æ˜¾å¼æŒ‡å®šä¸‹è½½
    python download_models.py --all                    # ä¸‹è½½æ‰€æœ‰
"""

import argparse
import os
from pathlib import Path
from typing import List

from huggingface_hub import snapshot_download

# æ¨¡å‹æ˜ å°„è¡¨
MODEL_REGISTRY = {
    # âœ… [æ ¸å¿ƒ] ä½ çš„æ–°ä¸»åŠ› LLM Backbone
    "qwen2.5-0.5b": {
        "hf_path": "Qwen/Qwen2.5-0.5B-Instruct",
        "size": "~1.2GB",
        "description": "Qwen2.5 0.5B Instruct (VLA è®­ç»ƒæœ€ä½³å°æ¨¡å‹ backbone)",
    },
    # VLA è§†è§‰å¡” (Vision Backbone) - Prismatic é»˜è®¤ä½¿ç”¨ SigLIP
    "siglip-so400m": {
        "hf_path": "google/siglip-so400m-patch14-384",
        "size": "~1.8GB",
        "description": "SigLIP So400M (VLA æ¨è Vision Backbone)",
    },
    # æ—§è°ƒè¯•æ¨¡å‹
    "distilgpt2": {
        "hf_path": "distilgpt2",
        "size": "~320MB",
        "description": "DistilGPT2 (æ—§è°ƒè¯•æ¨¡å‹)",
    },
    # å…¶å®ƒå…¨é‡ VLM (å¦‚æœä½ æƒ³è·‘å¯¹æ¯”å®éªŒ)
    "qwen2-vl-2b": {
        "hf_path": "Qwen/Qwen2-VL-2B-Instruct",
        "size": "~4.5GB",
        "description": "Qwen2-VL 2B Instruct (åŸºå‡†å¯¹æ¯”æ¨¡å‹)",
    },
}


def download_model(model_name: str, force: bool = False) -> None:
    """
    ä¸‹è½½æŒ‡å®šæ¨¡å‹åˆ° HuggingFace ç¼“å­˜
    """
    if model_name not in MODEL_REGISTRY:
        raise ValueError(
            f"Unknown model: {model_name}. "
            f"Available models: {list(MODEL_REGISTRY.keys())}"
        )
    
    model_info = MODEL_REGISTRY[model_name]
    hf_path = model_info["hf_path"]
    size = model_info["size"]
    description = model_info.get("description", "")
    
    print(f"\n{'='*60}")
    print(f"ğŸ“¦ ä¸‹è½½æ¨¡å‹: {model_name}")
    print(f"   è¯´æ˜: {description}")
    print(f"   HF è·¯å¾„: {hf_path}")
    print(f"   é¢„è®¡å¤§å°: {size}")
    print(f"{'='*60}\n")
    
    try:
        print(f"æ­£åœ¨ä¸‹è½½ {hf_path}...")
        print(f"æç¤º: ä½¿ç”¨ snapshot_download ä¸‹è½½å®Œæ•´æ¨¡å‹æ–‡ä»¶")
        
        # æ ¸å¿ƒä¸‹è½½é€»è¾‘
        cache_dir = snapshot_download(
            repo_id=hf_path,
            repo_type="model",
            # æ’é™¤ä¸å¿…è¦çš„è¶…å¤§æ–‡ä»¶ï¼Œåªä¸‹è½½ safetensors
            ignore_patterns=["*.msgpack", "*.h5", "*.ot", "*.bin"], 
            local_files_only=False,
            force_download=force,
        )
        
        print(f"âœ… æ¨¡å‹å·²ä¸‹è½½åˆ°: {cache_dir}")
        print(f"ğŸ‰ {model_name} ä¸‹è½½å®Œæˆ!\n")
        
    except Exception as e:
        print(f"\nâŒ ä¸‹è½½ {model_name} æ—¶å‡ºé”™: {e}\n")
        print(f"å»ºè®®: è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥ï¼Œæˆ–è€…æ˜¯å¦é…ç½®äº† HF_ENDPOINT é•œåƒ\n")
        raise


def main():
    parser = argparse.ArgumentParser(
        description="ä¸‹è½½ VLA è®­ç»ƒæ‰€éœ€çš„æ¨¡å‹æƒé‡åˆ° HuggingFace ç¼“å­˜"
    )
    parser.add_argument(
        "--model",
        type=str,
        choices=list(MODEL_REGISTRY.keys()),
        help="æŒ‡å®šè¦ä¸‹è½½çš„æ¨¡å‹",
    )
    parser.add_argument(
        "--all",
        action="store_true",
        help="ä¸‹è½½æ‰€æœ‰æ³¨å†Œçš„æ¨¡å‹",
    )
    parser.add_argument(
        "--force",
        action="store_true",
        help="å¼ºåˆ¶é‡æ–°ä¸‹è½½ï¼ˆå³ä½¿å·²ç¼“å­˜ï¼‰",
    )
    
    args = parser.parse_args()
    
    # ç¡®å®šè¦ä¸‹è½½çš„æ¨¡å‹åˆ—è¡¨
    if args.all:
        models_to_download = list(MODEL_REGISTRY.keys())
    elif args.model:
        models_to_download = [args.model]
    else:
        # âœ… é»˜è®¤ä¿®æ”¹ä¸ºä¸‹è½½ Qwen2.5-0.5B
        print("æœªæŒ‡å®šæ¨¡å‹ï¼Œé»˜è®¤ä¸‹è½½ VLA æ‰€éœ€çš„æ ¸å¿ƒç»„ä»¶ï¼š")
        models_to_download = ["qwen2.5-0.5b", "siglip-so400m"]
    
    # æ˜¾ç¤ºä¸‹è½½è®¡åˆ’
    print("\n" + "="*60)
    print("ğŸ“‹ ä¸‹è½½è®¡åˆ’:")
    for model_name in models_to_download:
        info = MODEL_REGISTRY[model_name]
        print(f"  - {model_name:20s} ({info['size']})")
    print("="*60)
    
    # ç¡®è®¤ä¸‹è½½
    if args.all:
        response = input("\nâš ï¸  å°†ä¸‹è½½æ‰€æœ‰æ¨¡å‹ï¼Œç¡®è®¤ç»§ç»­ï¼Ÿ[y/N]: ")
        if response.lower() != 'y':
            print("å·²å–æ¶ˆä¸‹è½½")
            return
    
    # å¼€å§‹ä¸‹è½½
    print("\nğŸš€ å¼€å§‹ä¸‹è½½...\n")
    success_count = 0
    failed_models = []
    
    for i, model_name in enumerate(models_to_download, 1):
        print(f"\n{'#'*60}")
        print(f"# è¿›åº¦: {i}/{len(models_to_download)}")
        print(f"{'#'*60}")
        
        try:
            download_model(model_name, force=args.force)
            success_count += 1
        except Exception as e:
            print(f"âŒ è·³è¿‡ {model_name}")
            failed_models.append(model_name)
    
    # æ€»ç»“
    print("\n" + "="*60)
    print("ğŸ“Š ä¸‹è½½æ€»ç»“:")
    print(f"  âœ… æˆåŠŸ: {success_count}/{len(models_to_download)}")
    if failed_models:
        print(f"  âŒ å¤±è´¥: {', '.join(failed_models)}")
    
    # æ˜¾ç¤º HF ç¼“å­˜ä½ç½®
    hf_cache = os.environ.get(
        "HF_HOME",
        os.path.expanduser("~/.cache/huggingface")
    )
    print(f"ğŸ’¾ æ¨¡å‹ç¼“å­˜è·¯å¾„: {hf_cache}")
    print("="*60)


if __name__ == "__main__":
    main()